{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching\n",
    "\n",
    "[<img align=\"right\" src=\"img/robot_and_ball.jpg\" />](http://www.hongkiat.com/blog/danbo-amazon-cardboard-robot-photos/)\n",
    "The first step of the manipulation task is searching for the object (the blue ball) and moving the robot near to it, so that the ball fits between the gripper fingers.\n",
    "\n",
    "This task is very similar to the visually-guided line-following task, since the ball is brightly colored and it can be [segmented](https://en.wikipedia.org/wiki/Image_segmentation) from the background with some simple image processing operations. Then, the robot can be controlled for approaching the ball.\n",
    "\n",
    "A possible algorithm would be:\n",
    "\n",
    "    1. open the gripper and tilt the kinect for searching the ball\n",
    "    2. turn the robot until the ball is centered in the camera image\n",
    "    3. move the robot forward until the ball is near the bottom of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: before running the code below, please restart the simulation in Webots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pioneer3.Controllers import PioneerRobot\n",
    "\n",
    "robot = PioneerRobot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colored blob detection\n",
    "We already know how to locate a colored blob (the line in the previous week, the ball now) in the image, thanks to its **centroid**, which is computed from the image moments. But we should also consider the case that the ball is *not visible* in the image. One solution is checking the **area** of the blob, which is given by $M_{00}$, and returning the centroid values only if the area is greater than zero.\n",
    "\n",
    "Let's define a function named `color_blob` for computing the area and centroid of a colored blob. If the blob is not detected, the area will be zero, and the centroid coordinates will be `None` (the Python value for null). This function is an improved version of the code used for the line following task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def color_blob(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    M = cv2.moments(mask)\n",
    "    area = M['m00']\n",
    "    if area > 0:\n",
    "        cx = int(M['m10']/area)\n",
    "        cy = int(M['m01']/area)\n",
    "    else:\n",
    "        cx = None\n",
    "        cy = None\n",
    "    return area, cx, cy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: initial position\n",
    "\n",
    "Open the gripper and tilt the kinect for searching the ball: the fingers should be wide open, the gripper down close to the ground, and the kinect should be tilted properly for searching throughout the room."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.gripper.open()\n",
    "robot.gripper.down()\n",
    "robot.kinect.setTiltPosition(-0.35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a good configuration, the top plate of the robot would be only slightly visible at the bottom of the image, and the walls of the room should be visible too (that is the robot should not be neither looking too much to the floor, nor to the ceiling). You may check the image in the next cell, and change the above parameters if necessary, until the result is satisfactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = robot.kinect.getColorImage()\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: turning\n",
    "\n",
    "We are going to use a `while` loop for turning the robot, which will stop when the blob is detected and its coordinates are approximately in the center of the image. Most of the code is given in the next cell, but you must figure out some values.\n",
    "\n",
    "* First, since the color of the ball is blue, you need to find out its proper **hue** value (please remember that the hue range in OpenCV scales from 0 to 180)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "lower = numpy.array([110, 100, 100])\n",
    "upper = numpy.array([130, 255, 255])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Next, you should choose the interval for considering the blob as centered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_blob_centered(image):\n",
    "    area, cx, cy = color_blob(image)\n",
    "    if area > 0 and cx >= 70 and cx < 80:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Finally, you must provide the velocity values for turning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not is_blob_centered(image):\n",
    "    robot.setSpeed(-0.5,0.5)\n",
    "    image = robot.kinect.getColorImage()\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, you can check the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "print('Area: %d, cx: %d, cy: %d' % color_blob(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: approaching\n",
    "\n",
    "As the robot moves forward and approaches to the ball, the position of the ball in the image will go down.\n",
    "\n",
    "We can define a threshold for stopping the robot before the ball goes out of the image. The code is very similar to the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_blob_close(image, vertical_threshold):\n",
    "    area, cx, cy = color_blob(image)\n",
    "    if area > 0 and cy >= vertical_threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not is_blob_close(image, 68):\n",
    "    robot.setSpeed(1.0,1.0)\n",
    "    image = robot.kinect.getColorImage()\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Additional step: fine motion\n",
    "\n",
    "If the ball is not between the fingers yet, you need to move the robot closer. This can be done in open loop, but this is prone to errors. A better option is to tilt the kinect lower, and repeat a new iteration of the approaching motion with a slightly higher vertical threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.kinect.setTiltPosition(-0.47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not is_blob_close(image, 72):\n",
    "    robot.setSpeed(1.0,1.0)\n",
    "    image = robot.kinect.getColorImage()\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next: [Grasping](Grasping.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Try-a-Bot: an open source guide for robot programming\n",
    "Developed by:\n",
    "[![Robotic Intelligence Lab @ UJI](img/logo/robinlab.png \"Robotic Intelligence Lab @ UJI\")](http://robinlab.uji.es)\n",
    "\n",
    "Sponsored by:\n",
    "<table>\n",
    "<tr>\n",
    "<td style=\"border:1px solid #ffffff ;\">\n",
    "<a href=\"http://www.ieee-ras.org\"><img src=\"img/logo/ras.png\"></a>\n",
    "</td>\n",
    "<td style=\"border:1px solid #ffffff ;\">\n",
    "<a href=\"http://www.cyberbotics.com\"><img src=\"img/logo/cyberbotics.png\"></a>\n",
    "</td>\n",
    "<td style=\"border:1px solid #ffffff ;\">\n",
    "<a href=\"http://www.theconstructsim.com\"><img src=\"img/logo/theconstruct.png\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Follow us:\n",
    "<table>\n",
    "<tr>\n",
    "<td style=\"border:1px solid #ffffff ;\">\n",
    "<a href=\"https://www.facebook.com/RobotProgrammingNetwork\"><img src=\"img/logo/facebook.png\"></a>\n",
    "</td>\n",
    "<td style=\"border:1px solid #ffffff ;\">\n",
    "<a href=\"https://www.youtube.com/user/robotprogrammingnet\"><img src=\"img/logo/youtube.png\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
