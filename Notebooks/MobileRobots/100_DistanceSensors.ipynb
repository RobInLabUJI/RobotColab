{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "100_DistanceSensors.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNFSMQ5lrV24s7Y0B0RXzty",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RobInLabUJI/RobotColab/blob/main/Notebooks/MobileRobots/100_DistanceSensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWIsD192o_-W"
      },
      "source": [
        "# Distance sensors\n",
        "\n",
        "An autonomous mobile robot needs to acquire knowledge about its environment. \n",
        "This can be done by taking measurements using sensors and then extracting \n",
        "information from those measurements.\n",
        "\n",
        "There is a wide variety of sensors in mobile robots. Ultrasonic devices are \n",
        "commonly used for measuring distances to solid obstacles.\n",
        "\n",
        "<img src=\"https://github.com/RobInLabUJI/RobotColab/raw/main/Notebooks/MobileRobots/Images/distance_sensors.png\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ1d1wq2qlGx"
      },
      "source": [
        "## Ultrasonic sensors\n",
        "\n",
        "<img src=\"https://github.com/RobInLabUJI/RobotColab/raw/main/Notebooks/MobileRobots/Images/sonars.png\" align=\"right\">\n",
        "\n",
        "Ultrasonic sensors work by measuring the return time\n",
        "of a high-frequency sound wave emitted by the sensor\n",
        "(over 20,000 Hz, which is therefore inaudible to\n",
        "humans). As the speed of sound is essentially known,\n",
        "the obstacle’s distance can then be deduced.\n",
        "\n",
        "The distance $d$ of the object causing the reflection is:\n",
        "\n",
        "$$\n",
        "d = \\frac{c \\cdot t}{2}\n",
        "$$\n",
        "\n",
        "where $c$ is the speed of the sound (343 m/s in air at standard pressure and 20ºC) and $t$ is the time of flight.\n",
        "\n",
        "The Pioneer 3-DX robot includes 8 forward-facing ultrasonic sensors, and 8 optional rear-facing sonar for distance measurements.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/cyberbotics/webots/released/docs/reference/images/sonar_reflection.png\" align=\"right\" width=\"360\">\n",
        "\n",
        "The sensors are numbered from 0 to 15 starting from the left\n",
        "side of the robot, in clockwise order, and distance $d$ measured by sensor $i$ can be obtained with the function\n",
        "```\n",
        "d = robot.sonar[i].getValue()\n",
        "```\n",
        "\n",
        "In the Webots simulator, the returned value corresponds to the sonar sensor's range if the incidence is greater than 22.5 degrees ($\\pi/8$ radians). In other words, sonar rays which lie outside the reflexion cone of aperture 45 degrees never return and thus are lost for distance computation.\n",
        "\n",
        "The rays can be displayed by checking the menu `View / Optional Rendering / Show Distance Sensor Rays`. The red/green transition on the rays indicates the points of intersection with the bounding objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2M7aaAzo_dn"
      },
      "source": [
        "from Pioneer3.Controllers import PioneerRobot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98N-ifn7njQN"
      },
      "source": [
        "robot = PioneerRobot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqPkdIlv55Pe"
      },
      "source": [
        "The values of the front sensors (3 and 4) are:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hvXNtBBsHdb"
      },
      "source": [
        "robot.sonar[3].getValue()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppqmDAMe5wwk"
      },
      "source": [
        "robot.sonar[3].getValue()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsvWVGRq5_Qr"
      },
      "source": [
        "The values of the back sensors (11 and 12) are:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFrgrhV75-PB"
      },
      "source": [
        "robot.sonar[11].getValue()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHnp1Fkw6FmI"
      },
      "source": [
        "robot.sonar[12].getValue()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtR4GDJl1Tfc"
      },
      "source": [
        "# Detecting obstacles\n",
        "\n",
        "<img src=\"https://github.com/RobInLabUJI/RobotColab/raw/main/Notebooks/MobileRobots/Images/distance_threshold.png\" align=\"right\">\n",
        "\n",
        "An obstacle can be detected by comparing the values\n",
        "returned by the ultrasonic sensor with a predefined\n",
        "*distance threshold*.\n",
        "\n",
        "For values below that threshold, the detected obstacle is\n",
        "considered too close to the robot, and an action should be\n",
        "taken, for example stopping and/or turning, in order to\n",
        "avoid collision.\n",
        "\n",
        "In the example figure, the value of sensor 3 is less than\n",
        "the threshold (represented by the dotted circle), as signaled by the green arrow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmQLtrUp3lYX"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Make a program for the robot to move **forward** until any of the front sensors (3 or 7) detects an obstacle below a given distance threshold, for example 1 meter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4J521xZsc9j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMgpClWA6Ucq"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Make a program for the robot to move **backward** until any of the front sensors (11 or 12) detects an obstacle below a given distance threshold, for example 1 meter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dirYMM0D6aRc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}