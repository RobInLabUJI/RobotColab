{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_DistanceSensors.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOc9pCCYWly3MRui2NkHvfQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RobInLabUJI/RobotColab/blob/main/Notebooks/MobileRobots/10_DistanceSensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWIsD192o_-W"
      },
      "source": [
        "# Distance sensors\n",
        "\n",
        "An autonomous mobile robot needs to acquire knowledge about its environment. \n",
        "This can be done by taking measurements using sensors and then extracting \n",
        "information from those measurements.\n",
        "\n",
        "There is a wide variety of sensors in mobile robots. Ultrasonic devices are \n",
        "commonly used for measuring distances to solid obstacles.\n",
        "\n",
        "<img src=\"https://github.com/RobInLabUJI/RobotColab/raw/main/Notebooks/MobileRobots/Images/distance_sensors.png\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ1d1wq2qlGx"
      },
      "source": [
        "## Ultrasonic sensors\n",
        "\n",
        "<img src=\"https://github.com/RobInLabUJI/RobotColab/raw/main/Notebooks/MobileRobots/Images/sonars.png\" align=\"right\">\n",
        "\n",
        "Ultrasonic sensors work by measuring the return time\n",
        "of a high-frequency sound wave emitted by the sensor\n",
        "(over 20,000 Hz, which is therefore inaudible to\n",
        "humans). As the speed of sound is essentially known,\n",
        "the obstacle’s distance can then be deduced.\n",
        "\n",
        "The distance $d$ of the object causing the reflection is:\n",
        "\n",
        "$$\n",
        "d = \\frac{c \\cdot t}{2}\n",
        "$$\n",
        "\n",
        "where $c$ is the speed of the sound (343 m/s in air at standard pressure and 20ºC) and $t$ is the time of flight.\n",
        "\n",
        "The Pioneer 3-DX robot includes 8 forward-facing ultrasonic sensors, and 8 optional rear-facing sonar for distance measurements.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/cyberbotics/webots/released/docs/reference/images/sonar_reflection.png\" align=\"right\" width=\"360\">\n",
        "\n",
        "The sensors are numbered from 0 to 15 starting from the left\n",
        "side of the robot, in clockwise order, and the value of sensor $i$ can be obtained with the function\n",
        "```\n",
        "robot.sonar[i].getValue()\n",
        "```\n",
        "\n",
        "In the Webots simulator, the returned value corresponds to the sonar sensor's range if the incidence is greater than 22.5 degrees ($\\pi/8$ radians). In other words, sonar rays which lie outside the reflexion cone of aperture 45 degrees never return and thus are lost for distance computation.\n",
        "\n",
        "The rays can be displayed by checking the menu `View / Optional Rendering / Show Distance Sensor Rays`. The red/green transition on the rays indicates the points of intersection with the bounding objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2M7aaAzo_dn"
      },
      "source": [
        "from Pioneer3.Controllers import PioneerRobot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98N-ifn7njQN"
      },
      "source": [
        "robot = PioneerRobot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hvXNtBBsHdb"
      },
      "source": [
        "for i in range(0, 16):\n",
        "  print(\"%2d: %.2f\" % (i, robot.sonar[i].getValue()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtR4GDJl1Tfc"
      },
      "source": [
        "# Detecting obstacles\n",
        "\n",
        "<img src=\"https://github.com/RobInLabUJI/RobotColab/raw/main/Notebooks/MobileRobots/Images/distance_threshold.png\" align=\"right\">\n",
        "\n",
        "An obstacle can be detected by comparing the values\n",
        "returned by the ultrasoinc sensor with a predefined\n",
        "*distance threshold*.\n",
        "\n",
        "For values below that threshold, the detected obstacle is\n",
        "considered too close to the robot, and an action should be\n",
        "taken, for example stopping and/or turning, in order to\n",
        "avoid collision.\n",
        "\n",
        "In the example figure, the value of sensor 3 is less than\n",
        "the threshold (represented by the dotted circle), as signaled by the green arrow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmQLtrUp3lYX"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Make a program for the robot to move forward until any of the front sensors (numbered 3 and 4) detects an obstacle below a given distance threshold, for example 1 meter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4J521xZsc9j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxjTZUzq3rd3"
      },
      "source": [
        "# Searching for free space\n",
        "\n",
        "After an obstacle is detected, the robot must turn either left or right in search for free space, so it can move forward again.\n",
        "\n",
        "Here is one possible solution:\n",
        "\n",
        "<img src=\"https://github.com/RobInLabUJI/RobotColab/raw/main/Notebooks/MobileRobots/Images/distance_free_space.png\" align=\"right\">\n",
        "\n",
        "* Find the minimum of the three left sensors (0, 1, 2)\n",
        "* Find the minimum of the three right sensors (5, 6, 7)\n",
        "* If the left minimum is lower than the right minimum then select the clockwise direction for turning, otherwise select the counterclockwise direction\n",
        "* Keep turning in the selected direction until both front sensors (3, 4) are bigger than the chosen minimum\n",
        "\n",
        "In the sample figure, the robot would turn clockwise, since the minimum of the right side sensors (green arc) is bigger than the one of the left side (red arc)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_8vmxHg51ZQ"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Implement the algorithm presented above for turninig the robots towards free space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx9XFB4X5kE8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVelLuAD5-kz"
      },
      "source": [
        "# Wandering behavior\n",
        "\n",
        "<img src=\"https://github.com/RobInLabUJI/RobotColab/raw/main/Notebooks/MobileRobots/Images/wandering.png\" align=\"right\">\n",
        "\n",
        "A simple wandering behavior can be achieved by the combination\n",
        "of the obstacle detection and free space search behaviors:\n",
        "```\n",
        "repeat forever\n",
        "  move forward until an obstacle is detected\n",
        "  turn either left or right for free space\n",
        "```\n",
        "\n",
        "Instead of starting from scratch, you should reuse the code of the previous exercises, which can be called from inside the main loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFddBLmS7Fi9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}